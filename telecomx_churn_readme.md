# ğŸ“¡ Telecom X - Parte 2: Prevendo Cancelamento de Clientes

Bem-vindo(a) ao repositÃ³rio do desafio **Telecom X - Parte 2**! ğŸš€

Este projeto faz parte de um estudo de **Data Science e Machine Learning** com foco em **reduÃ§Ã£o de churn** (evasÃ£o de clientes). Aqui, foi construÃ­do um pipeline preditivo capaz de identificar quais clientes possuem maior chance de cancelar seus serviÃ§os.

---

## ğŸ¯ MissÃ£o

- Desenvolver **modelos preditivos** para prever o cancelamento de clientes.
- Ajudar a empresa a **antecipar a evasÃ£o** e tomar decisÃµes estratÃ©gicas.

## ğŸ§  Objetivos do Desafio

- Preparar e tratar os dados para modelagem (remoÃ§Ã£o de colunas, encoding, normalizaÃ§Ã£o).
- Realizar **anÃ¡lise de correlaÃ§Ã£o** e seleÃ§Ã£o de variÃ¡veis.
- Treinar pelo menos dois modelos de classificaÃ§Ã£o.
- Avaliar o desempenho com mÃ©tricas de classificaÃ§Ã£o.
- Interpretar resultados e gerar insights de negÃ³cio.

## ğŸ› ï¸ Tecnologias e Ferramentas Utilizadas

- **Linguagem**: Python ğŸ
- **Bibliotecas**: Pandas, NumPy, Scikit-Learn, Matplotlib, Seaborn
- **Modelos Testados**:
  - RegressÃ£o LogÃ­stica
  - Random Forest
  - KNN (K-Nearest Neighbors)
  - Ãrvore de DecisÃ£o

---

## ğŸ”§ PreparaÃ§Ã£o dos Dados

- **RemoÃ§Ã£o de colunas irrelevantes**: IDs e variÃ¡veis redundantes foram eliminadas.
- **Encoding**: variÃ¡veis categÃ³ricas foram transformadas em numÃ©ricas.
- **NormalizaÃ§Ã£o**: aplicada em modelos sensÃ­veis Ã  escala (como KNN e RegressÃ£o LogÃ­stica).

---

## ğŸ¤– Modelagem

Foram criados **4 modelos preditivos**:

1. **RegressÃ£o LogÃ­stica** âœ…

   - Melhor desempenho geral.
   - FÃ¡cil de interpretar.
   - Ãštil para identificar variÃ¡veis mais relevantes.

2. **Random Forest** ğŸŒ²

   - Robusto contra overfitting.
   - Captura relaÃ§Ãµes complexas.
   - Bom desempenho, mas menor recall.

3. **KNN (K-Nearest Neighbors)** ğŸ‘¥

   - Simples e intuitivo.
   - Requer normalizaÃ§Ã£o.
   - Sofreu com dados desbalanceados.

4. **Ãrvore de DecisÃ£o** ğŸŒ³

   - FÃ¡cil de interpretar.
   - SuscetÃ­vel a overfitting.
   - Pior desempenho geral.

---

## ğŸ“Š AvaliaÃ§Ã£o dos Modelos

As mÃ©tricas utilizadas foram:

- **AcurÃ¡cia**
- **PrecisÃ£o**
- **Recall**
- **F1-Score**
- **Matriz de ConfusÃ£o**

ğŸ“Œ **Resultado Geral**:

- ğŸ¥‡ **RegressÃ£o LogÃ­stica** â†’ melhor equilÃ­brio entre precisÃ£o e recall.
- ğŸ¥ˆ **Random Forest** â†’ desempenho sÃ³lido, mas recall menor.
- ğŸ¥‰ **KNN** â†’ razoÃ¡vel, mas sofreu com desbalanceamento.
- ğŸš« **Ãrvore de DecisÃ£o** â†’ desempenho mais fraco.

---

## ğŸ“ ConclusÃµes

- O **modelo mais indicado** foi a **RegressÃ£o LogÃ­stica**, por apresentar o melhor equilÃ­brio entre as mÃ©tricas.
- VariÃ¡veis relacionadas a **tempo de contrato, tipo de serviÃ§o e forma de pagamento** foram cruciais para prever o cancelamento.
- EstratÃ©gias de retenÃ§Ã£o devem priorizar clientes com **baixo tempo de permanÃªncia e contratos mensais**, pois apresentam maior risco de evasÃ£o.

---

## ğŸ’¡ Insights EstratÃ©gicos

- Investir em **fidelizaÃ§Ã£o de clientes recÃ©m-chegados**.
- Criar benefÃ­cios para quem migra de **contratos mensais para anuais**.
- Monitorar clientes com **formas de pagamento mais flexÃ­veis**, que tendem a cancelar com mais facilidade.

---

## ğŸš€ Como Reproduzir o Projeto

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/telecomx-churn.git
   ```
2. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```
3. Abra o Jupyter Notebook:
   ```bash
   jupyter notebook Challenge_TelecomX_2_BR.ipynb
   ```

---

## ğŸ“Œ ConclusÃ£o Final

Este desafio mostrou como **Machine Learning pode ser aplicado de forma prÃ¡tica para reduzir churn** e apoiar a tomada de decisÃ£o estratÃ©gica. Mais do que algoritmos, o valor estÃ¡ em **transformar dados em aÃ§Ã£o**, permitindo que a empresa retenha clientes e aumente sua receita.

---

âœ¨ *Projeto desenvolvido como desafio prÃ¡tico de Data Science. Aprendizado garantido e muita diversÃ£o no processo!* ğŸ˜ƒ

